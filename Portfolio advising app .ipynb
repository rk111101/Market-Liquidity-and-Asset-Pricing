{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1733aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: curl_cffi in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from curl_cffi) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from curl_cffi) (2024.7.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\acer\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi) (2.21)\n"
     ]
    }
   ],
   "source": [
    "# FIX yahoo Finance Error\n",
    "!pip install curl_cffi\n",
    "from curl_cffi import requests\n",
    "session = requests.Session(impersonate=\"chrome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4538aaad-348b-45e7-b6ad-1ce52188bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "notebook_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4c566d-79d3-4398-8e27-c6e87acc6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 0: ILLIQ is constructed as equal-weighted High-Low Amihud portfolios to capture small-cap liquidity effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d5b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Illiquidity Premium Statistics (2017–2024):\n",
      "Value-Weighted ILLIQ: Premium = -9.6663%, t-stat = -23.2507, p-value = 0.0000\n",
      "Equal-Weighted ILLIQ: Premium = 0.6098%, t-stat = 2.9605, p-value = 0.0031\n"
     ]
    }
   ],
   "source": [
    "def compute_t_stat(series, annualization_factor=252):\n",
    "    mean = series.mean() * annualization_factor * 100  # Annualized premium in percentage\n",
    "    std = series.std() * np.sqrt(annualization_factor) * 100\n",
    "    n = len(series)\n",
    "    t_stat = mean / (std / np.sqrt(n))\n",
    "    p_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), n - 1))\n",
    "    return mean, t_stat, p_value\n",
    "\n",
    "# Load and compute ILLIQ statistics\n",
    "illiq_factor_vw = pd.read_csv(os.path.join(notebook_dir, \"illiq_factor_vw.csv\"))\n",
    "illiq_factor_vw['date'] = pd.to_datetime(illiq_factor_vw['date'])\n",
    "illiq_factor_vw = illiq_factor_vw.set_index('date')['ILLIQ_VW']\n",
    "mean_vw, t_stat_vw, p_value_vw = compute_t_stat(illiq_factor_vw)\n",
    "\n",
    "illiq_factor_ew = pd.read_csv(os.path.join(notebook_dir, \"illiq_factor_ew.csv\"))\n",
    "illiq_factor_ew['date'] = pd.to_datetime(illiq_factor_ew['date'])\n",
    "illiq_factor_ew = illiq_factor_ew.set_index('date')['ILLIQ_EW']\n",
    "mean_ew, t_stat_ew, p_value_ew = compute_t_stat(illiq_factor_ew)\n",
    "\n",
    "print(\"\\nIlliquidity Premium Statistics (2017–2024):\")\n",
    "print(f\"Value-Weighted ILLIQ: Premium = {mean_vw:.4f}%, t-stat = {t_stat_vw:.4f}, p-value = {p_value_vw:.4f}\")\n",
    "print(f\"Equal-Weighted ILLIQ: Premium = {mean_ew:.4f}%, t-stat = {t_stat_ew:.4f}, p-value = {p_value_ew:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f21cd06a-5a79-4a77-bde2-b4cca6d6415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple Average Premiums for All Factors (2017–2024):\n",
      "Mkt-RF: 12.3985%\n",
      "SMB: -2.9770%\n",
      "HML: -3.2496%\n",
      "RMW: 4.4295%\n",
      "CMA: -0.4460%\n",
      "Mom: -0.0000%\n",
      "ILLIQ: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# Load Fama-French data\n",
    "ff_data = pd.read_csv(r\"fama_french_data.csv\")\n",
    "ff_data['date'] = pd.to_datetime(ff_data['date'])\n",
    "ff_data = ff_data.set_index('date')\n",
    "\n",
    "# Compute simple average premiums for all factors\n",
    "factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'Mom', 'ILLIQ']\n",
    "simple_avg_premiums = ff_data[factors].mean() * 252 * 100\n",
    "\n",
    "print(\"\\nSimple Average Premiums for All Factors (2017–2024):\")\n",
    "for factor, premium in simple_avg_premiums.items():\n",
    "    print(f\"{factor}: {premium:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e89292f-4ac3-49db-9ef3-c8e096453f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 1: Data Preparation ---\n",
    "# This section loads and cleans data, computes factor premiums, and saves results for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171ff4f5-d15a-4d7b-a35b-ec2ce2e8fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1: CRSP Data Cleaning\n",
    "def clean_crsp_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert returns to numeric\n",
    "    df[\"RET\"] = pd.to_numeric(df[\"RET\"], errors=\"coerce\")\n",
    "    df[\"DLRET\"] = pd.to_numeric(df[\"DLRET\"], errors=\"coerce\")\n",
    "    \n",
    "    # Drop rows with missing critical values\n",
    "    df = df.dropna(subset=[\"PRC\", \"VOL\", \"SHROUT\", \"CFACPR\", \"CFACSHR\"])\n",
    "    \n",
    "    # Handle delisting returns\n",
    "    df[\"DLSTCD\"] = df[\"DLSTCD\"].fillna(0)\n",
    "    mask = df[\"DLSTCD\"].between(200, 399)\n",
    "    df[\"RET\"] = np.where(mask, df[\"DLRET\"], df[\"RET\"])\n",
    "    df[\"RET\"] = df[\"RET\"].fillna(-0.30)\n",
    "    \n",
    "    # Adjust for corporate actions\n",
    "    df[\"CFACPR\"] = df[\"CFACPR\"].replace(0, 1)\n",
    "    df[\"CFACSHR\"] = df[\"CFACSHR\"].replace(0, 1)\n",
    "    df[\"adj_prc\"] = df[\"PRC\"] / df[\"CFACPR\"]\n",
    "    df[\"adj_shrout\"] = (df[\"SHROUT\"] * 1000) * df[\"CFACSHR\"]\n",
    "    df[\"adj_volume\"] = df[\"VOL\"] * df[\"CFACSHR\"]\n",
    "    \n",
    "    # Convert to float32\n",
    "    df[\"adj_prc\"] = df[\"adj_prc\"].astype(\"float32\")\n",
    "    df[\"adj_volume\"] = df[\"adj_volume\"].astype(\"float32\")\n",
    "    \n",
    "    # Calculate dollar volume\n",
    "    df[\"dollar_volume\"] = df[\"adj_prc\"].abs() * df[\"adj_volume\"]\n",
    "    \n",
    "    # Handle invalid values\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Calculate daily market cap\n",
    "    df[\"daily_market_cap\"] = df[\"adj_prc\"] * df[\"adj_shrout\"]\n",
    "    df[\"daily_market_cap\"] = df[\"daily_market_cap\"].where(df[\"daily_market_cap\"] >= 0, np.nan)\n",
    "    \n",
    "    # Apply filters to remove if exceptional return or volume does not makes sense\n",
    "    df[\"RET\"] = np.where(df[\"RET\"].abs() > 2, np.nan, df[\"RET\"])\n",
    "    df[\"adj_volume\"] = np.where(df[\"adj_volume\"] > df[\"adj_shrout\"], np.nan, df[\"adj_volume\"])\n",
    "    df[\"dollar_volume\"] = df[\"adj_prc\"].abs() * df[\"adj_volume\"]\n",
    "    df[\"adj_volume\"] = np.where(df[\"dollar_volume\"] < 100, np.nan, df[\"adj_volume\"])\n",
    "    \n",
    "    # Customized filters to reduce more noices\n",
    "    # 1. Exclude microcaps (market cap < $50M)\n",
    "    df = df[df[\"daily_market_cap\"] >= 50_000_000]\n",
    "    # 2. Exclude stocks with low trading volume (dollar volume < $1M)\n",
    "    df = df[df[\"dollar_volume\"] >= 1_000_000]\n",
    "    # 3. Winsorize returns to reduce impact of outliers\n",
    "    df[\"RET\"] = df[\"RET\"].clip(lower=df[\"RET\"].quantile(0.01), upper=df[\"RET\"].quantile(0.99))\n",
    "    \n",
    "    df = df.dropna(subset=[\"RET\", \"adj_volume\", \"daily_market_cap\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6da80629-b4dc-43f2-9a7b-4c5aa0db92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2: Load Fama-French Data and ILLIQ Factor\n",
    "def load_fama_french_data(ff_path, mom_path, illiq_path):\n",
    "    # Load Fama-French 5-factor data\n",
    "    ff_data = pd.read_csv(ff_path)\n",
    "    \n",
    "    # Strip whitespace from column names\n",
    "    ff_data.columns = ff_data.columns.str.strip()\n",
    "    \n",
    "    # Verify expected columns for 5-factor data\n",
    "    ff_expected_columns = ['date', 'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF']\n",
    "    if not all(col in ff_data.columns for col in ff_expected_columns):\n",
    "        raise ValueError(f\"Fama-French 5-Factor CSV missing expected columns. Found: {ff_data.columns}, Expected: {ff_expected_columns}\")\n",
    "    \n",
    "    # Load Momentum factor data\n",
    "    mom_data = pd.read_csv(mom_path)\n",
    "    \n",
    "    # Strip whitespace from column names\n",
    "    mom_data.columns = mom_data.columns.str.strip()\n",
    "    \n",
    "    # Verify expected columns for Momentum data\n",
    "    mom_expected_columns = ['date', 'Mom']\n",
    "    if not all(col in mom_data.columns for col in mom_expected_columns):\n",
    "        raise ValueError(f\"Momentum CSV missing expected columns. Found: {mom_data.columns}, Expected: {mom_expected_columns}\")\n",
    "    \n",
    "    # Load ILLIQ factor data (value-weighted)\n",
    "    illiq_data = pd.read_csv(illiq_path)\n",
    "    \n",
    "    # Strip whitespace from column names\n",
    "    illiq_data.columns = illiq_data.columns.str.strip()\n",
    "    \n",
    "    # Verify expected columns for ILLIQ data\n",
    "    illiq_expected_columns = ['date', 'ILLIQ_VW']\n",
    "    if not all(col in illiq_data.columns for col in illiq_expected_columns):\n",
    "        raise ValueError(f\"ILLIQ CSV missing expected columns. Found: {illiq_data.columns}, Expected: {illiq_expected_columns}\")\n",
    "    \n",
    "    # Rename ILLIQ_VW to ILLIQ for consistency in the app\n",
    "    illiq_data = illiq_data.rename(columns={'ILLIQ_VW': 'ILLIQ'})\n",
    "    \n",
    "    # Convert dates to datetime\n",
    "    ff_data['date'] = pd.to_datetime(ff_data['date'], format='%Y%m%d')\n",
    "    mom_data['date'] = pd.to_datetime(mom_data['date'], format='%Y%m%d')\n",
    "    illiq_data['date'] = pd.to_datetime(illiq_data['date'])\n",
    "    \n",
    "    # Merge the datasets on date\n",
    "    ff_data = ff_data.merge(mom_data[['date', 'Mom']], on='date', how='inner')\n",
    "    ff_data = ff_data.merge(illiq_data[['date', 'ILLIQ']], on='date', how='inner')\n",
    "    ff_data = ff_data.set_index('date')[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF', 'Mom', 'ILLIQ']]\n",
    "    \n",
    "    # Convert to decimals (assuming Fama-French and Momentum data are in percentage points)\n",
    "    ff_data[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'Mom', 'RF']] = ff_data[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'Mom', 'RF']] / 100\n",
    "    \n",
    "    # Winsorize factor returns to reduce outliers (1st and 99th percentiles)\n",
    "    factors_to_winsorize = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'Mom', 'ILLIQ']\n",
    "    for factor in factors_to_winsorize:\n",
    "        ff_data[factor] = ff_data[factor].clip(lower=ff_data[factor].quantile(0.01), upper=ff_data[factor].quantile(0.99))\n",
    "\n",
    "    # Orthogonalize ILLIQ and Mom against correlated factors    \n",
    "    # Orthogonalize ILLIQ against Mkt-RF, HML, and CMA (correlations > 0.2)\n",
    "    X = sm.add_constant(ff_data[['Mkt-RF', 'HML', 'CMA']])\n",
    "    model = sm.OLS(ff_data['ILLIQ'], X).fit()\n",
    "    ff_data['ILLIQ'] = model.resid\n",
    "    \n",
    "    # Orthogonalize Mom against SMB and HML (correlations > 0.3)\n",
    "    X = sm.add_constant(ff_data[['SMB', 'HML']])\n",
    "    model = sm.OLS(ff_data['Mom'], X).fit()\n",
    "    ff_data['Mom'] = model.resid\n",
    "    \n",
    "    # Check for missing values in factor returns\n",
    "    if ff_data[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'Mom', 'ILLIQ', 'RF']].isna().any().any():\n",
    "        raise ValueError(\"Fama-French data contains missing values in factor returns or RF. Please ensure the data is complete.\")\n",
    "    \n",
    "    return ff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ff4c18-e492-4563-b8cf-9563511daa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3: Fama-MacBeth for All Factors\n",
    "def run_fama_macbeth(crsp_data, ff_data, significance_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Run Fama-MacBeth regression for all factors using the entire US stock universe.\n",
    "    \n",
    "    Notes:\n",
    "    - Factors include Mkt-RF, SMB, HML, RMW, CMA, Mom, and ILLIQ (constructed as High Amihud minus Low Amihud portfolio returns, value-weighted).\n",
    "    - Stock excess returns (R_i - R_f) are sourced from CRSP data.\n",
    "    \"\"\"\n",
    "    # Clean CRSP data\n",
    "    crsp_data = clean_crsp_data(crsp_data)\n",
    "    \n",
    "    # Check sample size\n",
    "    unique_stocks = crsp_data['PERMNO'].nunique()\n",
    "    if unique_stocks < 50:\n",
    "        raise ValueError(f\"Insufficient stocks in CRSP data ({unique_stocks} < 50). Please ensure the CRSP dataset contains enough stocks.\")\n",
    "    \n",
    "    # Align dates\n",
    "    common_dates = crsp_data.index.intersection(ff_data.index)\n",
    "    if len(common_dates) < 252:\n",
    "        raise ValueError(f\"Insufficient overlapping dates between CRSP and Fama-French data ({len(common_dates)} < 252 trading days).\")\n",
    "    \n",
    "    crsp_data = crsp_data.loc[common_dates]\n",
    "    ff_data = ff_data.loc[common_dates]\n",
    "    \n",
    "    # Define all factors (using value-weighted ILLIQ)\n",
    "    factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'Mom', 'ILLIQ']\n",
    "    \n",
    "    # Check for multicollinearity by computing factor correlations\n",
    "    print(\"Factor Correlations (2017–2024):\")\n",
    "    print(ff_data[factors].corr())\n",
    "    \n",
    "    # Step 1: Time-series regressions to estimate betas for each stock\n",
    "    betas_dict = {}\n",
    "    for permno in crsp_data['PERMNO'].unique():\n",
    "        stock_data = crsp_data[crsp_data['PERMNO'] == permno]\n",
    "        if len(stock_data) < 100:\n",
    "            continue\n",
    "        y = stock_data['RET'] - ff_data['RF']\n",
    "        X_factors = ff_data[factors]\n",
    "        \n",
    "        data = pd.concat([y, X_factors], axis=1).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if data.empty:\n",
    "            continue\n",
    "        \n",
    "        y = data.iloc[:, 0]\n",
    "        X = sm.add_constant(data.iloc[:, 1:])\n",
    "        model = sm.OLS(y, X).fit(cov_type='HAC', cov_kwds={'maxlags': 1})\n",
    "        betas_dict[permno] = model.params.drop('const')\n",
    "    \n",
    "    beta_df = pd.DataFrame(betas_dict).T\n",
    "    if beta_df.empty:\n",
    "        raise ValueError(\"No valid betas estimated. Check CRSP data for sufficient stock observations.\")\n",
    "    \n",
    "    # Step 2: Cross-sectional regressions to estimate factor premiums\n",
    "    premiums = []\n",
    "    for date in common_dates:\n",
    "        daily_data = crsp_data[crsp_data.index == date]\n",
    "        if len(daily_data) < 10:\n",
    "            continue\n",
    "        y = daily_data['RET'] - ff_data.loc[date, 'RF']\n",
    "        valid_permnos = daily_data['PERMNO'].isin(beta_df.index)\n",
    "        if not valid_permnos.any():\n",
    "            continue\n",
    "        \n",
    "        # Get the subset of data for valid PERMNOs\n",
    "        daily_data_valid = daily_data[valid_permnos]\n",
    "        y_valid = y[valid_permnos]\n",
    "        \n",
    "        # Reindex y_valid by PERMNO to match X's index\n",
    "        y_valid = pd.Series(y_valid.values, index=daily_data_valid['PERMNO'])\n",
    "        \n",
    "        # Ensure the index (PERMNO) is unique\n",
    "        if y_valid.index.duplicated().any():\n",
    "            raise ValueError(f\"Duplicate PERMNOs found on date {date}. Please ensure CRSP data has unique PERMNOs per date.\")\n",
    "        \n",
    "        X = sm.add_constant(beta_df.loc[daily_data_valid['PERMNO'], factors])\n",
    "        \n",
    "        # Concatenate y_valid and X, which are now both indexed by PERMNO\n",
    "        data = pd.concat([y_valid, X], axis=1).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if data.empty:\n",
    "            continue\n",
    "        \n",
    "        y = data.iloc[:, 0]\n",
    "        X = data.iloc[:, 1:]\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        premiums.append(model.params.drop('const'))\n",
    "    \n",
    "    premium_df = pd.DataFrame(premiums, columns=factors)\n",
    "    if premium_df.empty:\n",
    "        raise ValueError(\"No valid premiums estimated. Ensure there are enough cross-sectional observations.\")\n",
    "    \n",
    "    # Compute statistics and apply significance test\n",
    "    final_premiums = {}\n",
    "    significant_factors = []\n",
    "    print(\"\\nFama-MacBeth Results (2017–2024):\")\n",
    "    for factor in factors:\n",
    "        avg_premium = premium_df[factor].mean() * 252 * 100  # Annualized premium in percentage\n",
    "        std_premium = premium_df[factor].std() * np.sqrt(252) * 100\n",
    "        n = len(premium_df)\n",
    "        t_stat = avg_premium / (std_premium / np.sqrt(n))\n",
    "        p_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), n - 1))\n",
    "        \n",
    "        # Display premium with higher precision\n",
    "        print(f\"{factor}: Premium = {avg_premium:.8f}%, t-stat = {t_stat:.4f}, p-value = {p_value:.4f}\")\n",
    "        if p_value < significance_threshold:\n",
    "            final_premiums[factor] = avg_premium\n",
    "            significant_factors.append(factor)\n",
    "        else:\n",
    "            print(f\"{factor} excluded (p = {p_value:.4f} > {significance_threshold})\")\n",
    "    \n",
    "    return pd.Series(final_premiums), significant_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb91dbf-8ef5-4492-ac4f-f2f8552945dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4: Data Preparation Main Function\n",
    "def prepare_data(ff_path, mom_path, illiq_path, crsp_path):\n",
    "    \"\"\"Prepare data by loading, cleaning, and computing factor premiums.\"\"\"\n",
    "    # Load CRSP data\n",
    "    dtypes = {\n",
    "        \"PERMNO\": \"Int64\",\n",
    "        \"RET\": \"object\",\n",
    "        \"DLRET\": \"object\",\n",
    "        \"PRC\": \"float64\",\n",
    "        \"VOL\": \"float64\",\n",
    "        \"SHROUT\": \"float64\",\n",
    "        \"SHRCD\": \"Int16\",\n",
    "        \"EXCHCD\": \"Int8\",\n",
    "        \"CFACPR\": \"float64\",\n",
    "        \"CFACSHR\": \"float64\",\n",
    "        \"DLSTCD\": \"Int16\"\n",
    "    }\n",
    "    crsp_data = pd.read_csv(\n",
    "        crsp_path,\n",
    "        dtype=dtypes\n",
    "    )\n",
    "    crsp_data['date'] = pd.to_datetime(crsp_data['date'], format='%Y%m%d')\n",
    "    crsp_data = crsp_data.set_index('date')\n",
    "    \n",
    "    # Load Fama-French, Momentum, and ILLIQ data\n",
    "    ff_data = load_fama_french_data(ff_path, mom_path, illiq_path)\n",
    "    \n",
    "    # Run Fama-MacBeth for all factors\n",
    "    all_premiums, significant_factors = run_fama_macbeth(crsp_data, ff_data)\n",
    "    \n",
    "    # Save results\n",
    "    all_premiums.to_csv(os.path.join(notebook_dir, \"factor_premiums.csv\"), float_format='%.8f')\n",
    "    pd.Series(significant_factors).to_csv(os.path.join(notebook_dir, \"significant_factors.csv\"), index=False)\n",
    "    ff_data.to_csv(os.path.join(notebook_dir, \"fama_french_data.csv\"))\n",
    "    \n",
    "    print(\"\\nData preparation complete. Files saved:\")\n",
    "    print(f\"- {os.path.join(notebook_dir, 'factor_premiums.csv')}\")\n",
    "    print(f\"- {os.path.join(notebook_dir, 'significant_factors.csv')}\")\n",
    "    print(f\"- {os.path.join(notebook_dir, 'fama_french_data.csv')}\")\n",
    "    \n",
    "    return all_premiums, significant_factors, ff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebdc44a7-27d0-4ef7-ba54-96504fd51ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 2: Stock Analysis ---\n",
    "# This section analyzes a specific stock using the pre-computed premiums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d187ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Get Market VIX for fear estimation\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_fixed(5),\n",
    "    retry=retry_if_exception_type(Exception),\n",
    "    before_sleep=lambda retry_state: print(f\"Retrying VIX fetch (attempt {retry_state.attempt_number}/3)...\")\n",
    ")\n",
    "def get_current_vix():\n",
    "    \"\"\"Fetch the current VIX value from Yahoo Finance with retries.\n",
    "    \n",
    "    Returns:\n",
    "        float: Current VIX value, or 20.0 if fetch fails after retries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        time.sleep(1)  # Delay to avoid rate limits\n",
    "        vix = yf.Ticker(\"^VIX\", session = session)\n",
    "        vix_data = vix.history(period=\"1d\")\n",
    "        if vix_data.empty:\n",
    "            raise ValueError(\"No VIX data available.\")\n",
    "        current_vix = vix_data['Close'].iloc[-1]\n",
    "        return current_vix\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching VIX data: {str(e)}\")\n",
    "        if retry_state.attempt_number == 3:\n",
    "            print(\"All VIX fetch attempts failed. Using default VIX value: 20.0\")\n",
    "            return 20.0\n",
    "        raise  # Retry if attempts remain\n",
    "\n",
    "def get_market_regime(vix, low_threshold=15, high_threshold=25):\n",
    "    \"\"\"Determine the market regime based on VIX level.\n",
    "    \n",
    "    Args:\n",
    "        vix (float): Current VIX value.\n",
    "        low_threshold (float): Threshold for low volatility (default: 15).\n",
    "        high_threshold (float): Threshold for high volatility (default: 25).\n",
    "    \n",
    "    Returns:\n",
    "        str: 'low', 'medium', or 'high' volatility.\n",
    "    \"\"\"\n",
    "    if vix is None:\n",
    "        return 'medium'  # Default to medium if VIX fetch fails\n",
    "    if vix < low_threshold:\n",
    "        return 'low'\n",
    "    elif vix < high_threshold:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e211f9-1e1e-4e1c-a9f7-a04929e9d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1: Get Stock Data\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_fixed(5),\n",
    "    retry=retry_if_exception_type(Exception),\n",
    "    before_sleep=lambda retry_state: print(f\"Retrying {ticker} fetch (attempt {retry_state.attempt_number}/3)...\")\n",
    ")\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    \"\"\"Fetch historical stock data from Yahoo Finance with retries and error handling.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol (e.g., 'AAPL').\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns 'Close', 'RET', 'volume_dollar', indexed by 'date'.\n",
    "                     Returns empty DataFrame if fetch fails after retries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        time.sleep(1)  # Delay to avoid rate limits\n",
    "        stock = yf.Ticker(ticker, session = session)\n",
    "        df = stock.history(start=start_date, end=end_date, raise_errors=True)\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No data available for {ticker} between {start_date} and {end_date}.\")\n",
    "        \n",
    "        df.reset_index(inplace=True)\n",
    "        df['Date'] = pd.to_datetime(df['Date']).dt.tz_localize(None)\n",
    "        \n",
    "        df = df.rename(columns={\n",
    "            'Date': 'date',\n",
    "            'Close': 'Close',\n",
    "            'Volume': 'Volume'\n",
    "        })\n",
    "        \n",
    "        df = df.set_index('date')\n",
    "        \n",
    "        df['RET'] = df['Close'].pct_change()\n",
    "        df['volume_dollar'] = df['Volume'] * df['Close']\n",
    "        \n",
    "        df = df[['Close', 'RET', 'volume_dollar']].dropna()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "        if retry_state.attempt_number == 3:\n",
    "            print(f\"All fetch attempts failed for {ticker}. Returning empty DataFrame.\")\n",
    "            return pd.DataFrame(columns=['Close', 'RET', 'volume_dollar'])\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dbfaab3-0f04-4f2f-8cd6-cc9934084bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2: Calculate Amihud Illiquidity (for reporting purposes only, not used as a factor)\n",
    "def calculate_amihud_illiquidity(df):\n",
    "    \"\"\"Calculate the Amihud illiquidity ratio for a stock (scaled by 1e6 for consistency).\"\"\"\n",
    "    df['abs_return'] = df['RET'].abs()\n",
    "    df['amihud'] = np.where(\n",
    "        df['volume_dollar'] == 0,\n",
    "        np.nan,\n",
    "        (df['abs_return'] / df['volume_dollar']) * 1e6\n",
    "    )\n",
    "    # Keep 'RET' in the output DataFrame\n",
    "    return df[['amihud', 'RET']].replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3374482b-44e7-4e6e-8378-0024e7b63aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3: Calculate Stock Betas\n",
    "def calculate_stock_betas(ticker, stock_data, ff_data, factors):\n",
    "    \"\"\"Calculate factor betas for a single stock, returning betas and p-values.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol.\n",
    "        stock_data (pd.DataFrame): Stock data with columns 'RET', 'amihud', 'Ticker'.\n",
    "        ff_data (pd.DataFrame): Factor data with columns 'RF', factor columns, indexed by date.\n",
    "        factors (list of str): List of factor names (e.g., ['Mkt-RF', 'SMB', ...]).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (pd.Series of betas, pd.Series of p-values).\n",
    "    \"\"\"\n",
    "    # Align dates using merge\n",
    "    aligned_data = pd.merge(\n",
    "        stock_data.reset_index(),\n",
    "        ff_data.reset_index(),\n",
    "        on='date',\n",
    "        how='inner'\n",
    "    ).set_index('date')\n",
    "    \n",
    "    if len(aligned_data) < 252:\n",
    "        print(f\"Warning: Limited data for {ticker} ({len(aligned_data)} days).\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    required_columns = ['RET', 'RF'] + factors\n",
    "    missing_columns = [col for col in required_columns if col not in aligned_data.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Error: Missing columns {missing_columns} for {ticker}. Using default betas.\")\n",
    "        default_betas = pd.Series(1.0 if f == 'Mkt-RF' else 0.0, index=['const'] + factors)\n",
    "        default_pvalues = pd.Series(1.0, index=['const'] + factors)\n",
    "        return default_betas, default_pvalues\n",
    "    \n",
    "    y = aligned_data['RET'] - aligned_data['RF']\n",
    "    X_factors = aligned_data[factors]\n",
    "    X = sm.add_constant(X_factors)\n",
    "    \n",
    "    data = pd.concat([y, X], axis=1).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if data.empty:\n",
    "        print(f\"Warning: No valid data for {ticker}. Using default betas.\")\n",
    "        default_betas = pd.Series(1.0 if f == 'Mkt-RF' else 0.0, index=['const'] + factors)\n",
    "        default_pvalues = pd.Series(1.0, index=['const'] + factors)\n",
    "        return default_betas, default_pvalues\n",
    "    \n",
    "    y = data.iloc[:, 0]\n",
    "    X = data.iloc[:, 1:]\n",
    "    model = sm.OLS(y, X).fit(cov_type='HAC', cov_kwds={'maxlags': 1})\n",
    "    \n",
    "    betas = model.params\n",
    "    pvalues = model.pvalues\n",
    "    for factor in betas.index:\n",
    "        if pvalues[factor] > 0.05:\n",
    "            print(f\"Note: {factor} beta for {ticker} is not significant (p = {pvalues[factor]:.4f}).\")\n",
    "    \n",
    "    return betas, pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a014def9-ed25-4683-bceb-c0dbfb4eb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4: Calculate Expected Return\n",
    "def calculate_expected_return(stock_data, ff_data, avg_premiums, factors):\n",
    "    \"\"\"Calculate expected return using the multi-factor model, excluding Mom factor.\n",
    "    \n",
    "    Args:\n",
    "        stock_data (pd.DataFrame): Stock data with columns 'RET', 'amihud', 'Ticker'.\n",
    "        ff_data (pd.DataFrame): Factor data with columns 'RF', factor columns, indexed by date.\n",
    "        avg_premiums (pd.Series): Fama-MacBeth factor premiums (in %).\n",
    "        factors (list of str): List of factor names.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (float: expected return, dict: factor contributions, pd.Series: betas, pd.Series: p-values).\n",
    "    \"\"\"\n",
    "    # Align dates\n",
    "    aligned_data = pd.merge(\n",
    "        stock_data.reset_index(),\n",
    "        ff_data.reset_index(),\n",
    "        on='date',\n",
    "        how='inner'\n",
    "    ).set_index('date')\n",
    "    \n",
    "    # Check if stock_data is empty or missing Ticker\n",
    "    if stock_data.empty or 'Ticker' not in stock_data.columns:\n",
    "        print(\"Error: Stock data is empty or missing Ticker column. Cannot compute expected return.\")\n",
    "        return 0.0, {}, pd.Series(), pd.Series()\n",
    "    \n",
    "    ticker = stock_data['Ticker'].iloc[0]\n",
    "    betas, pvalues = calculate_stock_betas(ticker, stock_data, ff_data, factors)\n",
    "    \n",
    "    rf = aligned_data['RF'].mean() * 252\n",
    "    \n",
    "    expected_return = rf\n",
    "    contributions = {}\n",
    "    for factor in factors:\n",
    "        premium = avg_premiums.get(factor, 0.0) / 100\n",
    "        # Cap the Mom premium at 10% (a more reasonable historical value)\n",
    "        if factor == 'Mom':\n",
    "            premium = min(premium, 0.10)  # 10% annual premium\n",
    "            print(f\"Note: Capped Mom premium at 10% for {ticker} (original: {avg_premiums[factor]}%).\")\n",
    "        beta = betas.get(factor, 0.0)\n",
    "        contribution = beta * premium\n",
    "        expected_return += contribution\n",
    "        contributions[factor] = contribution * 100\n",
    "    \n",
    "    return expected_return, contributions, betas, pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7554807-a31e-4ed4-a86c-9c2cd10dc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5: Analyze a Specific Stock\n",
    "def advise_portfolio(ticker, start_date, end_date):\n",
    "    \"\"\"Provide portfolio advice for a specific stock using the multi-factor model.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol.\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results including expected return, betas, p-values, and illiquidity.\n",
    "    \n",
    "    Note on factor premiums:\n",
    "    - Factor premiums (Mkt-RF, SMB, HML, RMW, CMA, Mom, ILLIQ) are estimated using Fama-MacBeth\n",
    "      on the entire US stock universe (CRSP data).\n",
    "    - Factor returns for Mkt-RF, SMB, HML, RMW, CMA, and Mom are sourced from Fama-French CSVs.\n",
    "    - ILLIQ is constructed as High Amihud minus Low Amihud portfolio returns (value-weighted, including NASDAQ).\n",
    "    - Stock-specific variation in risk exposure is captured by the betas, estimated for each stock.\n",
    "    - ILLIQ and Mom are orthogonalized: ILLIQ against Mkt-RF, HML, CMA; Mom against SMB, HML, CMA.\n",
    "      Their contributions reflect exposure to these orthogonalized components.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load pre-computed data\n",
    "        avg_premiums = pd.read_csv(\"factor_premiums.csv\", index_col=0).squeeze()\n",
    "        significant_factors = pd.read_csv(\"significant_factors.csv\").squeeze().tolist()\n",
    "        ff_data = pd.read_csv(\"fama_french_data.csv\").set_index('date')\n",
    "        ff_data.index = pd.to_datetime(ff_data.index)\n",
    "        \n",
    "        # Verify date range overlap\n",
    "        ff_start = ff_data.index.min()\n",
    "        ff_end = ff_data.index.max()\n",
    "        start = pd.to_datetime(start_date)\n",
    "        end = pd.to_datetime(end_date)\n",
    "        if start > ff_end or end < ff_start:\n",
    "            raise ValueError(f\"No overlapping dates between stock data ({start_date} to {end_date}) and factor data ({ff_start} to {ff_end}).\")\n",
    "        \n",
    "        # Fetch stock data\n",
    "        df = fetch_stock_data(ticker, start_date, end_date)\n",
    "        \n",
    "        # Calculate Amihud (for reporting purposes only)\n",
    "        amihud_data = calculate_amihud_illiquidity(df)\n",
    "        amihud_data['Ticker'] = ticker\n",
    "        \n",
    "        # Calculate expected return\n",
    "        expected_return, contributions, betas, pvalues = calculate_expected_return(\n",
    "            amihud_data, ff_data, avg_premiums, significant_factors\n",
    "        )\n",
    "        \n",
    "        # Output advice\n",
    "        advice = {\n",
    "            'Ticker': ticker,\n",
    "            'Period': f\"{start_date} to {end_date}\",\n",
    "            'Amihud Illiquidity': amihud_data['amihud'].mean(),\n",
    "            'Betas': betas.to_dict(),\n",
    "            'Beta P-Values': pvalues.to_dict(),\n",
    "            'Expected Annual Return (%)': expected_return * 100,\n",
    "            'Factor Contributions (%)': contributions\n",
    "        }\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaf3cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6: Compute Sharpe Ratio of Portfolio\n",
    "def compute_historical_sharpe(tickers, weights, start_date, end_date, rf=0.02):\n",
    "    \"\"\"Compute historical Sharpe ratios for a portfolio and the S&P 500 over a specified period.\n",
    "    \n",
    "    Parameters:\n",
    "        tickers (list of str): List of stock ticker symbols.\n",
    "        weights (list of float): List of weights corresponding to each stock.\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "        rf (float): Annual risk-free rate, default is 0.02 (2%).\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            list of float: Portfolio Sharpe ratios for each month.\n",
    "            list of float: S&P 500 Sharpe ratios for each month.\n",
    "            list of str: Labels for each month (e.g., 'Jan', 'Feb').\n",
    "    \n",
    "    Side Effects:\n",
    "        Prints messages for data fetch failures or default value usage.\n",
    "    \"\"\"\n",
    "    portfolio_rets = pd.DataFrame()\n",
    "    successful_tickers = []\n",
    "    successful_weights = []\n",
    "    \n",
    "    for ticker, weight in zip(tickers, weights):\n",
    "        try:\n",
    "            rets = fetch_stock_data(ticker, start_date, end_date)  # Use fetch_stock_data\n",
    "            if not rets.empty:\n",
    "                portfolio_rets[ticker] = rets['RET']  # Use RET column\n",
    "                successful_tickers.append(ticker)\n",
    "                successful_weights.append(weight)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {ticker} for historical Sharpe calculation: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    sp500_rets = fetch_stock_data('^GSPC', start_date, end_date)  # Use fetch_stock_data\n",
    "    if sp500_rets.empty:\n",
    "        print(\"Warning: No S&P 500 data. Using default Sharpe values.\")\n",
    "        return [0.5, 0.6, 0.8, 0.7], [0.4, 0.5, 0.5, 0.6], ['Jan', 'Feb', 'Mar', 'Apr']\n",
    "    \n",
    "    total_weight = sum(successful_weights)\n",
    "    if total_weight == 0:\n",
    "        successful_weights = [1.0 / len(successful_tickers)] * len(successful_tickers)\n",
    "    else:\n",
    "        successful_weights = [w / total_weight for w in successful_weights]\n",
    "    \n",
    "    portfolio_rets['Portfolio'] = portfolio_rets.dot(successful_weights)\n",
    "    monthly_periods = pd.date_range(start=start_date, end=end_date, freq='ME')\n",
    "    portfolio_sharpes = []\n",
    "    sp500_sharpes = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(monthly_periods) - 1):\n",
    "        start = monthly_periods[i]\n",
    "        end = monthly_periods[i + 1]\n",
    "        period_portfolio = portfolio_rets['Portfolio'].loc[start:end]\n",
    "        period_sp500 = sp500_rets['RET'].loc[start:end]  # Use RET column\n",
    "        if not period_portfolio.empty and not period_sp500.empty:\n",
    "            portfolio_ret = period_portfolio.mean() * 252\n",
    "            portfolio_vol = period_portfolio.std() * np.sqrt(252)\n",
    "            sp500_ret = period_sp500.mean() * 252\n",
    "            sp500_vol = period_sp500.std() * np.sqrt(252)\n",
    "            portfolio_sharpe = (portfolio_ret - rf) / portfolio_vol if portfolio_vol != 0 else 0\n",
    "            sp500_sharpe = (sp500_ret - rf) / sp500_vol if sp500_vol != 0 else 0\n",
    "            portfolio_sharpes.append(portfolio_sharpe)\n",
    "            sp500_sharpes.append(sp500_sharpe)\n",
    "            labels.append(start.strftime('%b'))\n",
    "    \n",
    "    if not portfolio_sharpes:\n",
    "        print(\"No overlapping data for Sharpe ratio calculation. Using default values.\")\n",
    "        return [0.5, 0.6, 0.8, 0.7], [0.4, 0.5, 0.5, 0.6], ['Jan', 'Feb', 'Mar', 'Apr']\n",
    "    \n",
    "    return portfolio_sharpes, sp500_sharpes, labels\n",
    "def plot_sharpe_tracker(portfolio_sharpes, sp500_sharpes, labels):\n",
    "    \"\"\"Create a line chart tracking the portfolio's Sharpe ratio vs. the S&P 500 over time.\n",
    "    \n",
    "    Parameters:\n",
    "        portfolio_sharpes (list of float): Portfolio Sharpe ratios.\n",
    "        sp500_sharpes (list of float): S&P 500 Sharpe ratios.\n",
    "        labels (list of str): Time labels for the x-axis (e.g., ['Jan', 'Feb']).\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    Side Effects:\n",
    "        Saves a chart as 'sharpe_tracker.png' in the notebook directory and prints a confirmation message.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(labels, portfolio_sharpes, label='Portfolio Sharpe Ratio', color='#4CAF50')\n",
    "    plt.plot(labels, sp500_sharpes, label='S&P 500 Sharpe Ratio', color='#2196F3')\n",
    "    plt.title('Sharpe Ratio Tracker')\n",
    "    plt.ylabel('Sharpe Ratio')\n",
    "    plt.xlabel('Month')\n",
    "    plt.legend()\n",
    "    plt.ylim(0, max(max(portfolio_sharpes, default=0), max(sp500_sharpes, default=0)) * 1.2)\n",
    "    output_path = os.path.join(notebook_dir, 'sharpe_tracker.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Sharpe ratio tracker chart saved as {output_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "879580ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7: Weight Allocation for Portfolio and Output Feature\n",
    "def suggest_portfolio(tickers, start_date, end_date, risk_tolerance='moderate', min_weight=0.1, max_weight=0.5):\n",
    "    \"\"\"Suggest portfolio holdings by analyzing stocks and computing allocations based on risk-adjusted scores.\n",
    "    \n",
    "    Parameters:\n",
    "        tickers (list of str): List of stock ticker symbols (e.g., ['META', 'AAPL']).\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "        risk_tolerance (str): User's risk tolerance, one of 'conservative', 'moderate', 'aggressive', default is 'moderate'.\n",
    "        min_weight (float): Minimum allocation weight per stock, default is 0.1.\n",
    "        max_weight (float): Maximum allocation weight per stock, default is 0.5.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Portfolio summary with keys:\n",
    "              'Allocations' (dict of str to float), 'Portfolio Expected Return (%)' (float),\n",
    "              'Portfolio Factor Exposures' (dict of str to float), 'Portfolio Amihud Illiquidity' (float),\n",
    "              'Individual Stock Analysis' (dict of str to dict), 'Market Regime' (str),\n",
    "              'Risk Tolerance' (str), 'Insights' (list of str), 'Historical Sharpe' (dict),\n",
    "              'Weights' (list of float). Returns None if processing fails.\n",
    "    \n",
    "    Side Effects:\n",
    "        Prints VIX status, errors, and warnings during processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        avg_premiums = pd.read_csv(\"factor_premiums.csv\", index_col=0).squeeze()\n",
    "        significant_factors = pd.read_csv(\"significant_factors.csv\").squeeze().tolist()\n",
    "        ff_data = pd.read_csv(\"fama_french_data.csv\").set_index('date')\n",
    "        ff_data.index = pd.to_datetime(ff_data.index).tz_localize(None)\n",
    "        \n",
    "        current_vix = get_current_vix()\n",
    "        if current_vix is None:\n",
    "            print(\"Warning: Could not fetch VIX data. Assuming medium volatility.\")\n",
    "            market_regime = 'medium'\n",
    "        else:\n",
    "            market_regime = get_market_regime(current_vix)\n",
    "            print(f\"Current VIX: {current_vix:.2f}, Market Regime: {market_regime}\")\n",
    "        \n",
    "        stock_results = []\n",
    "        for ticker in tickers:\n",
    "            result = advise_portfolio(ticker, start_date, end_date)\n",
    "            if result:\n",
    "                stock_results.append(result)\n",
    "            else:\n",
    "                print(f\"Skipping {ticker} due to errors in analysis.\")\n",
    "        \n",
    "        if not stock_results:\n",
    "            raise ValueError(\"No valid stock analysis results to build portfolio.\")\n",
    "        \n",
    "        rf = ff_data['RF'].mean() * 252\n",
    "        scores = []\n",
    "        for result in stock_results:\n",
    "            ticker = result['Ticker']\n",
    "            expected_return = result['Expected Annual Return (%)'] / 100\n",
    "            mkt_beta = result['Betas'].get('Mkt-RF', 1.0)\n",
    "            amihud = result['Amihud Illiquidity']\n",
    "            sharpe = (expected_return - rf) / mkt_beta if mkt_beta != 0 else 0\n",
    "            illiquidity_penalty = 1 / (1 + amihud * 1e6)\n",
    "            risk_adjustment = (0.5 if market_regime == 'high' else 1.0) if risk_tolerance == 'conservative' else \\\n",
    "                              (1.5 if market_regime == 'low' else 1.0) if risk_tolerance == 'aggressive' else 1.0\n",
    "            score = sharpe * illiquidity_penalty * risk_adjustment\n",
    "            scores.append((ticker, score, expected_return, mkt_beta, amihud, result))\n",
    "        \n",
    "        total_score = sum(score for _, score, _, _, _, _ in scores)\n",
    "        weights = [score / total_score if total_score != 0 else 1.0 / len(tickers) for _, score, _, _, _, _ in scores]\n",
    "\n",
    "        # Adjust weights based on risk tolerance\n",
    "        if risk_tolerance == 'conservative':\n",
    "            weights = [w / (beta + 1) for w, beta in zip(weights, [r[3] for r in scores])]  # Penalize high-beta stocks\n",
    "        elif risk_tolerance == 'aggressive':\n",
    "            weights = [w * expected_return for w, expected_return in zip(weights, [r[2] for r in scores])]  # Favor high-return stocks\n",
    "        # For 'moderate', weights remain unchanged\n",
    "        weights = np.array(weights)\n",
    "        weights = weights / weights.sum()  # Normalize after adjustment\n",
    "        \n",
    "        weights = np.array(weights)\n",
    "        weights = np.maximum(weights, min_weight)\n",
    "        weights = np.minimum(weights, max_weight)\n",
    "        weights /= weights.sum()\n",
    "        \n",
    "        portfolio_return = 0.0\n",
    "        portfolio_betas = {factor: 0.0 for factor in significant_factors if factor != 'Mom'}\n",
    "        portfolio_illiquidity = 0.0\n",
    "        \n",
    "        for (ticker, _, expected_return, mkt_beta, amihud, result), weight in zip(scores, weights):\n",
    "            portfolio_return += weight * expected_return\n",
    "            for factor in portfolio_betas:\n",
    "                portfolio_betas[factor] += weight * result['Betas'].get(factor, 0.0)\n",
    "            portfolio_illiquidity += weight * amihud\n",
    "        \n",
    "        sharpe_start_date = (pd.to_datetime(end_date) - pd.Timedelta(days=180)).strftime('%Y-%m-%d')\n",
    "        portfolio_sharpes, sp500_sharpes, sharpe_labels = compute_historical_sharpe(tickers, weights, sharpe_start_date, end_date)\n",
    "        \n",
    "        # Generate dynamic insights\n",
    "        insights = []\n",
    "        top_stock = max(scores, key=lambda x: x[1])[0]\n",
    "        top_result = next(result for result in stock_results if result['Ticker'] == top_stock)\n",
    "        top_weight = [weight for (ticker, _, _, _, _, _), weight in zip(scores, weights) if ticker == top_stock][0]\n",
    "        insights.append(\n",
    "            f\"Highest allocation to {top_stock} ({top_weight:.2%}) due to its strong risk-adjusted return \"\n",
    "            f\"(Expected Return: {top_result['Expected Annual Return (%)']:.2f}%, Market Beta: {top_result['Betas']['Mkt-RF']:.2f}).\"\n",
    "        )\n",
    "        \n",
    "        liquidity_info = []\n",
    "        for ticker, _, _, _, amihud, result in scores:\n",
    "            liquidity_desc = \"highly illiquid - expect higher transaction costs\" if amihud > 0.01 else \\\n",
    "                            \"moderately liquid - manageable trading\" if amihud > 0.0001 else \\\n",
    "                            \"highly liquid - easy to trade\"\n",
    "            liquidity_info.append(f\"{ticker}: {amihud:.6f} ({liquidity_desc})\")\n",
    "        insights.append(\"Liquidity Assessment (Amihud Illiquidity):\\n  \" + \"\\n  \".join(liquidity_info))\n",
    "        \n",
    "        risk_note = f\"Portfolio balances risk and return for your moderate preference (Market Beta: {portfolio_betas['Mkt-RF']:.2f}).\"\n",
    "        if risk_tolerance == 'aggressive':\n",
    "            risk_note = f\"This portfolio suits your aggressive stance, emphasizing higher returns with a market beta of {portfolio_betas['Mkt-RF']:.2f}.\"\n",
    "            if market_regime == 'high':\n",
    "                risk_note += \" However, high market volatility (VIX ≥ 25) suggests caution - monitor for potential downturns.\"\n",
    "        elif risk_tolerance == 'conservative':\n",
    "            risk_note = f\"Portfolio aligns with your conservative preference, with a market beta of {portfolio_betas['Mkt-RF']:.2f}.\"\n",
    "            if market_regime == 'high':\n",
    "                risk_note += \" High market volatility (VIX ≥ 25) favors this defensive allocation.\"\n",
    "        insights.append(risk_note)\n",
    "        \n",
    "        growth_value = \"growth-oriented\" if portfolio_betas['HML'] < 0 else \"value-oriented\"\n",
    "        size_tilt = \"large-cap\" if portfolio_betas['SMB'] < 0 else \"small-cap\"\n",
    "        insights.append(\n",
    "            f\"Portfolio Style: {growth_value} (HML: {portfolio_betas['HML']:.2f}) and {size_tilt}-focused \"\n",
    "            f\"(SMB: {portfolio_betas['SMB']:.2f}).\"\n",
    "        )\n",
    "        \n",
    "        insights.append(\n",
    "            \"Notes:\\n- Premiums are based on 2017–2024 data and may reflect period-specific conditions.\\n\"\n",
    "        )\n",
    "        \n",
    "        portfolio_summary = {\n",
    "            'Allocations': {ticker: weight for (ticker, _, _, _, _, _), weight in zip(scores, weights)},\n",
    "            'Portfolio Expected Return (%)': portfolio_return * 100,\n",
    "            'Portfolio Factor Exposures': portfolio_betas,\n",
    "            'Portfolio Amihud Illiquidity': portfolio_illiquidity,\n",
    "            'Individual Stock Analysis': {result['Ticker']: result for result in stock_results},\n",
    "            'Market Regime': market_regime,\n",
    "            'Risk Tolerance': risk_tolerance,\n",
    "            'Insights': insights,\n",
    "            'Historical Sharpe': {'Portfolio': portfolio_sharpes, 'SP500': sp500_sharpes, 'Labels': sharpe_labels},\n",
    "            'Weights': weights.tolist()\n",
    "        }\n",
    "        return portfolio_summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error suggesting portfolio: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f78d800-f483-47e6-b0b4-65fe986c823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 3: Run the App ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30f81b2b-faf0-423b-b501-bb7b9916ef3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor Correlations (2017–2024):\n",
      "              Mkt-RF           SMB           HML       RMW           CMA  \\\n",
      "Mkt-RF  1.000000e+00  2.089147e-01 -1.412541e-01 -0.201180 -3.195120e-01   \n",
      "SMB     2.089147e-01  1.000000e+00  2.763783e-01 -0.281037  3.804965e-02   \n",
      "HML    -1.412541e-01  2.763783e-01  1.000000e+00  0.354558  5.926897e-01   \n",
      "RMW    -2.011801e-01 -2.810375e-01  3.545584e-01  1.000000  2.927694e-01   \n",
      "CMA    -3.195120e-01  3.804965e-02  5.926897e-01  0.292769  1.000000e+00   \n",
      "Mom    -1.031017e-01 -1.395965e-16 -5.318439e-17 -0.045953  1.859249e-01   \n",
      "ILLIQ   7.028495e-16  1.403455e-01 -3.909821e-16 -0.064968 -3.997497e-16   \n",
      "\n",
      "                 Mom         ILLIQ  \n",
      "Mkt-RF -1.031017e-01  7.028495e-16  \n",
      "SMB    -1.395965e-16  1.403455e-01  \n",
      "HML    -5.318439e-17 -3.909821e-16  \n",
      "RMW    -4.595339e-02 -6.496769e-02  \n",
      "CMA     1.859249e-01 -3.997497e-16  \n",
      "Mom     1.000000e+00 -4.278330e-02  \n",
      "ILLIQ  -4.278330e-02  1.000000e+00  \n",
      "\n",
      "Fama-MacBeth Results (2017–2024):\n",
      "Mkt-RF: Premium = 13.29600980%, t-stat = 33.6072, p-value = 0.0000\n",
      "SMB: Premium = 1.49357704%, t-stat = 5.7127, p-value = 0.0000\n",
      "HML: Premium = -3.26784862%, t-stat = -9.2292, p-value = 0.0000\n",
      "RMW: Premium = -0.91984489%, t-stat = -3.9044, p-value = 0.0001\n",
      "CMA: Premium = -2.47889149%, t-stat = -10.3854, p-value = 0.0000\n",
      "Mom: Premium = 52.45192976%, t-stat = 119.9938, p-value = 0.0000\n",
      "ILLIQ: Premium = 1.23482398%, t-stat = 2.5392, p-value = 0.0112\n",
      "\n",
      "Data preparation complete. Files saved:\n",
      "- C:\\Users\\s1155163244\\Downloads\\Group G FYP Materials\\Factors Investing Advisor\\factor_premiums.csv\n",
      "- C:\\Users\\s1155163244\\Downloads\\Group G FYP Materials\\Factors Investing Advisor\\significant_factors.csv\n",
      "- C:\\Users\\s1155163244\\Downloads\\Group G FYP Materials\\Factors Investing Advisor\\fama_french_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Run data preparation (only needs to be run once)\n",
    "# Paths to the data files\n",
    "ff_path = os.path.join(notebook_dir, \"F-F_Research_Data_5_Factors_2x3_daily.CSV\")\n",
    "mom_path = os.path.join(notebook_dir, \"F-F_Momentum_Factor_daily.CSV\")\n",
    "illiq_path = os.path.join(notebook_dir, \"illiq_factor_vw.csv\")\n",
    "crsp_path = os.path.join(notebook_dir, \"daily stock price.csv\")\n",
    "\n",
    "# Run data preparation\n",
    "all_premiums, significant_factors, ff_data = prepare_data(ff_path, mom_path, illiq_path, crsp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd5d7962-e76a-4c72-be1c-a006d499a3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter ticker symbols (e.g., META AAPL):  META AAPL\n",
      "Enter risk tolerance (conservative, moderate, aggressive):  aggressive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current VIX: 22.07, Market Regime: medium\n",
      "Note: const beta for META is not significant (p = 0.6305).\n",
      "Note: Mom beta for META is not significant (p = 0.1826).\n",
      "Note: ILLIQ beta for META is not significant (p = 0.7818).\n",
      "Note: Capped Mom premium at 10% for META (original: 52.45192976%).\n",
      "Note: const beta for AAPL is not significant (p = 0.2596).\n",
      "Note: Mom beta for AAPL is not significant (p = 0.0617).\n",
      "Note: ILLIQ beta for AAPL is not significant (p = 0.5481).\n",
      "Note: Capped Mom premium at 10% for AAPL (original: 52.45192976%).\n",
      "\n",
      "=== Portfolio Advisor Dashboard ===\n",
      "\n",
      "Portfolio Suggestion (2017–2024 premiums, Risk Tolerance: aggressive, Market Regime: medium):\n",
      "Allocations:\n",
      "  META: 43.76%\n",
      "  AAPL: 56.24%\n",
      "Portfolio Expected Return: 21.26%\n",
      "Portfolio Factor Exposures (Weighted Betas):\n",
      "  Mkt-RF: 1.3493\n",
      "  SMB: -0.2298\n",
      "  HML: -0.4281\n",
      "  RMW: 0.3745\n",
      "  CMA: -0.2086\n",
      "  ILLIQ: -0.0033\n",
      "Portfolio Amihud Illiquidity: 0.000002\n",
      "\n",
      "Key Insights:\n",
      "- Highest allocation to AAPL (56.24%) due to its strong risk-adjusted return (Expected Return: 20.91%, Market Beta: 1.37).\n",
      "- Liquidity Assessment (Amihud Illiquidity):\n",
      "  META: 0.000003 (highly liquid - easy to trade)\n",
      "  AAPL: 0.000001 (highly liquid - easy to trade)\n",
      "- This portfolio suits your aggressive stance, emphasizing higher returns with a market beta of 1.35.\n",
      "- Portfolio Style: growth-oriented (HML: -0.43) and large-cap-focused (SMB: -0.23).\n",
      "- Notes:\n",
      "- Premiums are based on 2017–2024 data and may reflect period-specific conditions.\n",
      "\n",
      "\n",
      "Sharpe Ratio Tracker:\n",
      "Sharpe ratio tracker chart saved as C:\\Users\\Acer\\Downloads\\FTEC4999\\Factors Investing Advisor\\sharpe_tracker.png.\n",
      "\n",
      "Automated Rebalancing:\n",
      "Current VIX: 22.07\n",
      "Suggestion: Hold current portfolio.\n",
      "Options: [1] Activate Monthly Rebalance, [2] Execute Now, [3] Skip\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-3):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Transaction costs considered in optimization.\n",
      "\n",
      "Liquidity Risk Assessment:\n",
      "Liquidity Risk Exposure: Low (Avg. Amihud: 0.000002)\n",
      "Sharpe Ratio: 0.14\n",
      "Options: [1] View Historical Performance, [2] Skip\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-2):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VIX-Based Insights:\n",
      "Current VIX: 22.07 (medium Volatility)\n",
      "Suggestion: Hold current portfolio.\n",
      "Options: [1] Rebalance Now, [2] Skip\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-2):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Individual Stock Analysis:\n",
      "\n",
      "Portfolio Advice for META using Multi-Factor Model (2017–2024 premiums):\n",
      "Period: 2017-01-01 to 2024-12-31\n",
      "Amihud Illiquidity: 0.000003\n",
      "Factor Betas and Significance:\n",
      "  const: Beta = 0.0002, p-value = 0.6305\n",
      "  Mkt-RF: Beta = 1.3263, p-value = 0.0000\n",
      "  SMB: Beta = -0.2585, p-value = 0.0087\n",
      "  HML: Beta = -0.3319, p-value = 0.0004\n",
      "  RMW: Beta = 0.2011, p-value = 0.0486\n",
      "  CMA: Beta = -0.9129, p-value = 0.0000\n",
      "  Mom: Beta = -0.0808, p-value = 0.1826\n",
      "  ILLIQ: Beta = 0.0138, p-value = 0.7818\n",
      "Factor Contributions (%):\n",
      "  Mkt-RF: 17.6345\n",
      "  SMB: -0.3860\n",
      "  HML: 1.0846\n",
      "  RMW: -0.1850\n",
      "  CMA: 2.2629\n",
      "  Mom: -0.8075\n",
      "  ILLIQ: 0.0170\n",
      "Expected Annual Return: 21.71%\n",
      "\n",
      "Portfolio Advice for AAPL using Multi-Factor Model (2017–2024 premiums):\n",
      "Period: 2017-01-01 to 2024-12-31\n",
      "Amihud Illiquidity: 0.000001\n",
      "Factor Betas and Significance:\n",
      "  const: Beta = 0.0003, p-value = 0.2596\n",
      "  Mkt-RF: Beta = 1.3671, p-value = 0.0000\n",
      "  SMB: Beta = -0.2075, p-value = 0.0008\n",
      "  HML: Beta = -0.5030, p-value = 0.0000\n",
      "  RMW: Beta = 0.5094, p-value = 0.0000\n",
      "  CMA: Beta = 0.3395, p-value = 0.0022\n",
      "  Mom: Beta = 0.0642, p-value = 0.0617\n",
      "  ILLIQ: Beta = -0.0166, p-value = 0.5481\n",
      "Factor Contributions (%):\n",
      "  Mkt-RF: 18.1776\n",
      "  SMB: -0.3099\n",
      "  HML: 1.6436\n",
      "  RMW: -0.4685\n",
      "  CMA: -0.8417\n",
      "  Mom: 0.6420\n",
      "  ILLIQ: -0.0205\n",
      "Expected Annual Return: 20.91%\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Suggested Portfolio Feature\n",
    "def main():\n",
    "    \"\"\"Entry point of the script, handling user input and displaying portfolio analysis results with interactive features.\n",
    "    \n",
    "    Parameters:\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    Side Effects:\n",
    "        Prints portfolio analysis, insights, and interactive prompts; saves charts to files.\n",
    "    \"\"\"\n",
    "    tickers_input = input(\"Enter ticker symbols (e.g., META AAPL): \").strip().split()\n",
    "    start_date = \"2017-01-01\"\n",
    "    end_date = \"2024-12-31\"\n",
    "    \n",
    "    while True:\n",
    "        risk_tolerance = input(\"Enter risk tolerance (conservative, moderate, aggressive): \").strip().lower()\n",
    "        if risk_tolerance in ['conservative', 'moderate', 'aggressive']:\n",
    "            break\n",
    "        print(\"Invalid risk tolerance. Please enter 'conservative', 'moderate', or 'aggressive'.\")\n",
    "    \n",
    "    portfolio_result = suggest_portfolio(tickers_input, start_date, end_date, risk_tolerance=risk_tolerance)\n",
    "    \n",
    "    if portfolio_result:\n",
    "        current_vix = get_current_vix() \n",
    "        print(\"\\n=== Portfolio Advisor Dashboard ===\")\n",
    "        if current_vix > 30:\n",
    "            print(\"\\nHigh VIX Detected: Consider rebalancing to preserve capital.\")\n",
    "        \n",
    "        print(f\"\\nPortfolio Suggestion (2017–2024 premiums, Risk Tolerance: {portfolio_result['Risk Tolerance']}, Market Regime: {portfolio_result['Market Regime']}):\")\n",
    "        print(\"Allocations:\")\n",
    "        for ticker, weight in portfolio_result['Allocations'].items():\n",
    "            print(f\"  {ticker}: {weight:.2%}\")\n",
    "        print(f\"Portfolio Expected Return: {portfolio_result['Portfolio Expected Return (%)']:.2f}%\")\n",
    "        print(\"Portfolio Factor Exposures (Weighted Betas):\")\n",
    "        for factor, beta in portfolio_result['Portfolio Factor Exposures'].items():\n",
    "            print(f\"  {factor}: {beta:.4f}\")\n",
    "        print(f\"Portfolio Amihud Illiquidity: {portfolio_result['Portfolio Amihud Illiquidity']:.6f}\")\n",
    "        \n",
    "        print(\"\\nKey Insights:\")\n",
    "        for insight in portfolio_result['Insights']:\n",
    "            print(f\"- {insight}\")\n",
    "        \n",
    "        print(\"\\nSharpe Ratio Tracker:\")\n",
    "        plot_sharpe_tracker(\n",
    "            portfolio_result['Historical Sharpe']['Portfolio'],\n",
    "            portfolio_result['Historical Sharpe']['SP500'],\n",
    "            portfolio_result['Historical Sharpe']['Labels']\n",
    "        )\n",
    "        \n",
    "        # Automated Rebalancing\n",
    "        print(\"\\nAutomated Rebalancing:\")\n",
    "        print(f\"Current VIX: {current_vix:.2f}\")\n",
    "        if current_vix > 30:\n",
    "            rebalance_suggestion = \"Switch to liquid stocks (Decile 0) to reduce drawdowns.\"\n",
    "        elif current_vix < 18:\n",
    "            rebalance_suggestion = \"Switch to illiquid stocks (Decile 9) for higher returns.\"\n",
    "        else:\n",
    "            rebalance_suggestion = \"Hold current portfolio.\"\n",
    "        print(f\"Suggestion: {rebalance_suggestion}\")\n",
    "        print(\"Options: [1] Activate Monthly Rebalance, [2] Execute Now, [3] Skip\")\n",
    "        choice = input(\"Enter your choice (1-3): \").strip()\n",
    "        if choice == '1':\n",
    "            print(\"Monthly rebalancing activated: Optimizing for Sharpe ratio with VIX strategy.\")\n",
    "        elif choice == '2':\n",
    "            print(f\"Rebalancing to: {rebalance_suggestion}\")\n",
    "        print(\"Note: Transaction costs considered in optimization.\")\n",
    "        \n",
    "        # Risk Analyzer\n",
    "        print(\"\\nLiquidity Risk Assessment:\")\n",
    "        avg_amihud = portfolio_result['Portfolio Amihud Illiquidity']\n",
    "        liquidity_risk = \"High\" if avg_amihud > 0.01 else \"Moderate\" if avg_amihud > 0.0001 else \"Low\"\n",
    "        sharpe = (portfolio_result['Portfolio Expected Return (%)'] / 100 - 0.02) / portfolio_result['Portfolio Factor Exposures']['Mkt-RF']\n",
    "        print(f\"Liquidity Risk Exposure: {liquidity_risk} (Avg. Amihud: {avg_amihud:.6f})\")\n",
    "        print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "        print(\"Options: [1] View Historical Performance, [2] Skip\")\n",
    "        choice = input(\"Enter your choice (1-2): \").strip()\n",
    "        if choice == '1':\n",
    "            print(\"Historical Performance:\")\n",
    "            print(\"Portfolio Sharpe Ratios:\", [round(x, 2) for x in portfolio_result['Historical Sharpe']['Portfolio']])\n",
    "            print(\"S&P 500 Sharpe Ratios:\", [round(x, 2) for x in portfolio_result['Historical Sharpe']['SP500']])\n",
    "            print(\"Months:\", portfolio_result['Historical Sharpe']['Labels'])\n",
    "        \n",
    "        # VIX Insights\n",
    "        print(\"\\nVIX-Based Insights:\")\n",
    "        print(f\"Current VIX: {current_vix:.2f} ({portfolio_result['Market Regime']} Volatility)\")\n",
    "        vix_suggestion = \"Reduce exposure to illiquid stocks.\" if current_vix > 30 else \\\n",
    "                         \"Increase exposure to illiquid stocks for higher returns.\" if current_vix < 18 else \\\n",
    "                         \"Hold current portfolio.\"\n",
    "        print(f\"Suggestion: {vix_suggestion}\")\n",
    "        print(\"Options: [1] Rebalance Now, [2] Skip\")\n",
    "        choice = input(\"Enter your choice (1-2): \").strip()\n",
    "        if choice == '1':\n",
    "            print(f\"Rebalancing: {vix_suggestion}\")\n",
    "        \n",
    "        # Individual Stock Analysis\n",
    "        print(\"\\nIndividual Stock Analysis:\")\n",
    "        for ticker, result in portfolio_result['Individual Stock Analysis'].items():\n",
    "            print(f\"\\nPortfolio Advice for {result['Ticker']} using Multi-Factor Model (2017–2024 premiums):\")\n",
    "            print(f\"Period: {result['Period']}\")\n",
    "            print(f\"Amihud Illiquidity: {result['Amihud Illiquidity']:.6f}\")\n",
    "            print(\"Factor Betas and Significance:\")\n",
    "            for factor in result['Betas']:\n",
    "                print(f\"  {factor}: Beta = {result['Betas'][factor]:.4f}, p-value = {result['Beta P-Values'][factor]:.4f}\")\n",
    "            print(\"Factor Contributions (%):\")\n",
    "            for factor, contrib in result['Factor Contributions (%)'].items():\n",
    "                print(f\"  {factor}: {contrib:.4f}\")\n",
    "            print(f\"Expected Annual Return: {result['Expected Annual Return (%)']:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9debb0-7db4-4481-a144-a9a611d3cac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
